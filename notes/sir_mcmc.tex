\documentclass{article}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{graphicx}

\begin{document}

Here we describe estimation of the states and unknown parameters of a state-space model of an epidemic outbreak using MCMC.

\section{Model \label{sec:model}}

Let $x_t = (s_t,i_t)'$ denote the state of the epidemic at time $t$. We consider a compartmental model of disease transmission that is governed by three parameters:

\begin{itemize}
\item $\beta$, the contact rate of spread of disease,
\item $\gamma$, the recovery time from infection, and
\item $\nu$, the mixing intensity of the population.
\end{itemize}

\noindent $\beta$, $\gamma$, and $\nu$ are each restricted to be nonnegative. Define $\theta = (\beta,\gamma,\nu)'$ to be the vector of unknown parameters in our model, and let $P$ be the size of the population. Then, we describe the evolution of the epidemic from time $t$ to $t + 1$ by
\begin{equation}
x_{t+1}\left|x_t,\theta\right. \sim N_\Omega\left(x_{t+1};f(x_t,\theta),Q(\theta)\right) \label{eqn:state}
\end{equation}
\noindent where
\[
f(x_t,\theta) = \left(
\begin{array}{c}
s_t - \beta i_ts^{\nu}_t \phantom{- \gamma i_t}\,\, \\
i_t +  \beta i_ts^\nu_t - \gamma i_t
\end{array}
\right)
\qquad
Q(\theta) = \frac{\beta}{P^2} \left(
\begin{array}{ccccc}
1 & -1 \\
-1 & 1 + \gamma/\beta
\end{array}
\right)
\]

\noindent and $\Omega = \{(s_t,i_t): s_t \ge 0, i_t \ge 0, s_t + i_t \le 1\}$. $N_{\Omega}(.; \mu,\Sigma)$ represents the pdf of the truncated normal distribution onto the set $\Omega$ with mean and covariance matrix of its corresponding untruncated normal distribution given by $\mu$ and $\Sigma$, respectively.

We consider observed data that are positive real numbers related to counts of emergency room visits, prescription sales, or calls to a hotline, for example, and we can observe data from these different streams/sources asynchronously in time. That is, at any time $t$, we can observe data from any subset of the streams (or possibly none of them). Let $y_{l,t}$ represent data coming from stream $l$ at time $t$, where $l = 1,2,\ldots,L$ and $t = 1,2,\ldots,T$. We model the log of the observations (so that $y_{l,t}$ is restricted to be positive) by
\begin{equation}
\log y_{l,t} \sim N\left(\log y_{l,t};b_li_t^{\varsigma_l} + \eta_l,\sigma_l^2\right) \label{eqn:obs}
\end{equation}
where $b_l$, $\varsigma_l$, and $\sigma_l$ are nonnegative constants and $\eta_l$ is a real number that determines the baseline level of incoming syndromic data from stream $l$. We assume $b_l$, $\varsigma_l$, $\sigma_l$, and $\eta_l$ are known for all $l$.

\section{Bayesian estimation}

We specify the following priors on the initial state $x_0$ and unknown parameters $\theta$:

\begin{align*}
p(x_0) &= p(i_0,s_0) = N(i_0;0.002,0.005^2)\delta_{1 - i_0}(s_0) \\
p(\theta) &= p(\beta)p(\gamma)p(\nu) \\
p(\beta) &= LN(\beta;-1.3296,0.3248^2) \\
p(\gamma) &= LN(\gamma;-2.1764,0.1183^2) \\
p(\nu) &= LN(\nu;0.1055,0.0800^2)
\end{align*}

We can now derive full conditional distributions of the states and unknown parameters using Bayes' rule. Using the fact that the joint density of the observations, states, and unknown parameters can be calculated by

\begin{equation}
p(y_{1:T},x_{0:T},\theta) = \prod_{t = 1}^T \left\{p(y_t|x_t,\theta)p(x_t|x_{t-1},\theta)\right\}p(x_0,\theta) \label{eqn:joint}
\end{equation}

\noindent which, in our case, can be reduced to
\[\prod_{t = 1}^T \left\{p(y_t|i_t)p(x_t|x_{t-1},\theta)\right\}p(x_0)p(\beta)p(\gamma)p(\nu)\]

It is convenient for us to write the distribution $p(x_t|x_{t-1},\theta)$ as $p(i_t|s_t,x_{t-1},\theta)p(s_t|x_{t-1},\theta)$ since we will sample new states in the MCMC from the truncated bivariate normal distribution by first sampling $s_t$ from its marginal distribution and then sampling $i_t$ conditional on $s_t$. Thus, we derive the following distributions

\begin{align*}
p(s_t|x_{t-1},\theta) &= p(s_t|s_{t-1},i_{t-1},\theta) = N_{[0,1]}(s_t; s_{t-1} - \beta i_{t-1}s^{\nu}_{t-1} - \gamma i_{t-1}, \beta / P^2) \\
p(i_t|s_t,x_{t-1},\theta) &= p(i_t|s_t,s_{t-1},i_{t-1},\theta) = N_{[0,1-s_t]}(i_{t-1}(1 - \gamma) + s_{t-1} - s_t, \gamma / P^2)
\end{align*}

\section{Full conditionals}
We can now express the full conditional distributions of the states $i_t$ and $s_t$ for $t = 0, 1, \ldots, T$ and unknown parameters $\beta$, $\gamma$, and $\nu$ up to a proportionality constant by

\begin{align*}
p(s_0|\hdots) &\propto p(i_1|i_0,s_1,s_0,\theta)p(s_1|s_0,i_0,\theta)p(i_0,s_0)\\
p(s_t|\hdots) &\propto p(i_{t+1}|i_t,s_{t+1},s_t,\theta)p(i_t|i_{t-1},s_t,s_{t-1},\theta)p(s_{t+1}|s_t,i_t,\theta)p(s_t|s_{t-1},i_{t-1},\theta) \mbox{, for } t = 1,\ldots,T-1 \\
p(s_T|\hdots) &\propto p(i_T|i_{T-1},s_T,s_{T-1},\theta)p(s_T|s_{T-1},i_{T-1},\theta) \\
p(i_0|\hdots) &\propto p(i_1|i_0,s_1,s_0,\theta)p(s_1|s_0,i_0,\theta)p(i_0,s_0) \\
p(i_t|\hdots) &\propto p(y_t|i_t)p(i_{t+1}|i_t,s_{t+1},s_t,\theta)p(i_t|i_{t-1},s_t,s_{t-1},\theta)p(s_{t+1}|s_t,i_t,\theta) \mbox{, for } t = 1,\ldots,T \\
p(i_T|\hdots) &\propto p(y_T|i_T)p(i_T|i_{T-1},s_T,s_{T-1},\theta) \\
p(\beta|\hdots) &\propto \prod_{t-1}^T \{p(i_t|i_{t-1},s_t,s_{t-1},\theta)p(s_t|s_{t-1},i_{t-1},\theta)\}p(\beta) \\
p(\gamma|\hdots) &\propto \prod_{t-1}^T \{p(i_t|i_{t-1},s_t,s_{t-1},\theta)p(s_t|s_{t-1},i_{t-1},\theta)\}p(\gamma) \\
p(\nu|\hdots) &\propto \prod_{t-1}^T \{p(i_t|i_{t-1},s_t,s_{t-1},\theta)p(s_t|s_{t-1},i_{t-1},\theta)\}p(\nu)
\end{align*}

\end{document} 