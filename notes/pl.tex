\documentclass{article}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{graphicx}

\graphicspath{
{/Users/Danny/Documents/"UCSB - Research"/smc/graphs/dlmRW/},
{/Users/Danny/Documents/"UCSB - Research"/smc/graphs/}
}

\begin{document}

\section{Particle Learning}

We consider a particle filtering algorithm called particle learning \citep{Carv:Joha:Lope:Pols:part} that can be used for a particular class of state-space models which includes dynamic linear models (DLMs) \citep{petris2009dynamic}. These models are characterized by observation and state equations, specified by the distributions $p(y_t|x_t,\theta)$ and $p(x_t|x_{t-1},\theta)$, respectively, where $y_t$ represents observed data at time $t$, $x_t$ is the unobserved state, and $\theta$ represents any unknown fixed parameters. We are interested in approximating the \emph{filtered distribution} of the unknown states and fixed parameters at time $t$, i.e. $p(x_t,\theta|y_{1:t})$, through the discrete sample approximation
\begin{equation}
p(x_t,\theta|y_{1:t}) \approx \sum_{j=1}^J w_t^{(j)}\delta_{\left(x_t^{(j)},\theta_t^{(j)}\right)},
\end{equation}
\noindent where $\left(x_t^{(j)},\theta_t^{(j)}\right)$ represents sampled values corresponding to the $j^{\mbox{th}}$ particle, $w_t^{(j)}$ is the associated weight of the $j^{\mbox{th}}$ particle, and $\delta_x$ is a Dirac delta function that puts point mass at $x$. We require that $\sum_{j=1}^J w_t^{(j)} = 1$ for all $t$ and note that the subscript $t$ on $\theta_t^{(j)}$ does not imply that $\theta$ is dynamic, but rather that the sampled values for $\theta$ can change over time.

Like all other particle filters, particle learning prescribes a recursive formula for updating the discrete approximation to the filtered distribution over time. To avoid particle degeneracy in the fixed parameters, sampled values for $\theta$ are refreshed at each time point using conditional sufficient statistics. Let $s_t$ denote the sufficient statistics for $\theta$ conditional on the current state $x_t$. Then, we add the sampled values of the sufficient statistics, $s_t^{(j)}$, to the particles, i.e. particle $j$ and time $t$ is now represented by $\left(x_t^{(j)},s_t^{(j)},\theta_t^{(j)}\right)$. We move from an approximation to $p(x_t,\theta|y_{1:t})$ to that of $p(x_{t+1},\theta|y_{1:t+1})$ by the following procedure for each particle $j = 1,2,\ldots,J$:
\begin{enumerate}
\item Resample: sample an index $k \in \{1,\ldots,j,\ldots,J\}$ with associated probabilities $\{g_{t+1}^{(1)},\ldots,g_{t+1}^{(j)},\ldots,g_{t+1}^{(J)}\}$, where \[\tilde{g}_{t+1}^{(j)} = p\left(y_{t+1}|x_t^{(j)},\theta_t^{(j)}\right) \qquad g_{t+1}^{(j)} = \tilde{g}_{t+1}^{(j)} \left/ \sum_{l=1}^J \tilde{g}_{t+1}^{(l)}\right.,\]
\item Propagate: sample $x_{t+1}^{(j)} \sim p\left(x_{t+1}|y_{t+1},x_t^{(k)},\theta\right)$,
\item Update: calculate $s_{t+1}^{(j)} = S\left(y_{t+1},x_{t+1}^{(j)},s_t^{(k)}\right)$,
\item Regenerate: sample $\theta_{t+1}^{(j)} \sim p\left(\theta|s_{t+1}^{(j)}\right)$.
\end{enumerate}
The algorithm is initialized by specifying initial particles $\left(x_0^{(j)},s_0^{(j)},\theta_0^{(j)}\right)$ and weights $w_0^{(j)}$ for all $j$, usually done by sampling from the prior $p(x_0,\theta)$ with equal weights. Note that the algorithm requires the ability to evaluate the conditional predictive distribution $p(y_{t+1}|x_t,\theta)$ as well as the ability to sample from the conditional posterior distribution $p(x_{t+1}|y_{t+1},x_t,\theta)$. Thus, particle learning is only applicable to models for which the form of these distributions is analytically tractable. In addition, we must define the recursive map $S$ to update the sufficient statistics based on the new observation $y_{t+1}$ and the newly sampled state $x_{t+1}^{(j)}$.

Efficiency of the algorithm can be enhanced by marginalizing out the current state $x_t$ and tracking conditional state sufficient statistics. This process, known as Rao-Blackwellization, requires tractability of the distributions $p(y_{t+1}|s_{x,t},\theta)$, which is used in place of $p(y_{t+1}|x_t,\theta)$ in the ``Resample'' step, and $p(x_{t+1}|y_{t+1},s_{x,t},\theta)$, which is used in place of $p(x_{t+1}|y_{t+1},x_t,\theta)$ in the ``Propagate'' step, where $s_{x,t}$ is the conditional (on $\theta$) sufficient statistics for $x_t$.

Furthermore, the ``Resample'' step can be regarded as optional and only needed if particle weights are out of balance. For iterations of the algorithm for which we choose to forgo resampling, we 1) omit the ``Resample'' step, 2) replace all instances of the sampled index $k$ with the particle index $j$, and 3) add a final ``Calculate weights'' step where particle $j$ is assigned associated weight $w_{t+1}^{(j)}$, where \[\tilde{w}_{t+1}^{(j)} = w_t^{(j)}p\left(y_{t+1}|x_t^{(j)},\theta_t^{(j)}\right) \qquad w_{t+1}^{(j)} = \tilde{w}_{t+1}^{(j)} \left/ \sum_{l=1}^J \tilde{w}_{t+1}^{(l)}\right..\] If Rao-Blackwellization is performed, then $\tilde{w}_{t+1}^{(j)} = w_t^{(j)}p\left(y_{t+1}|s_{x,t}^{(j)},\theta_t^{(j)}\right)$ in the ``Calculate weights'' step.

\section{Example - local level DLM with common state and observation variance}

For an illustration of particle learning, we consider the local level or random-walk DLM. In this example, an analytical form for $p(x_t,\theta|y_{1:t})$ exists, and so a particle filtering algorithm is not needed for this situation in practice. However, we offer this example so that we can evaluate the performance of particle learning through comparison with known distributions.

The local level model is specified by state and observation equations
\begin{align}
y_t &= x_t + v_t \label{eqn:llobs} \\
x_t &= x_{t-1} + w_t \label{eqn:llstate}
\end{align}
\noindent where $y_t$ and $x_t$ are univariate, $v_t \stackrel{\mbox{iid}}{\sim} \mbox{N}(0,\theta)$, $w_t \stackrel{\mbox{iid}}{\sim} \mbox{N}(0,\theta\lambda)$, and $v_t \perp w_s$ for all $s$ and $t$. We regard $\theta$ as an unknown parameter representing the common state and observation variance (up to a constant) and $\lambda$, which represents the signal to noise ratio, is regarded as known. We define the following prior distribution on the initial state $x_0$ and fixed parameter $\theta$:
\begin{equation}
x_0|\theta \sim \mbox{N}(m_0,\theta C_0) \qquad \theta \sim \mbox{IG}(a_0,b_0) \label{eqn:llprior}
\end{equation}
where $\mbox{IG}(a,b)$ represents the inverse-gamma distribution with shape parameter $a$ and rate parameter $b$. The hyperparameters $m_0$, $C_0$, $a_0$, and $b_0$ are regarded as known.

As mentioned, an explicit form for the posterior $p(x_t,\theta|y_{1:t})$ can be calculated and updated recursively using the well-known Kalman filter equations \cite[Chap. 2]{petris2009dynamic}. Denote the prior distribution $p(x_0, \theta)$ defined in equation \eqref{eqn:llprior} by $(x_0, \theta) \sim \mbox{NG}(m_0, C_0, a_0, b_0)$. Given $(x_{t-1},\theta)|y_{1:t-1} \sim \mbox{NG}(m_{t-1},C_{t-1}, a_{t-1}, b_{t-1})$ for $t \ge 1$ (with the convention $p(x_0,\theta|y_{1:0}) = p(x_0, \theta)$), the posterior distribution $p(x_t,\phi|y_{1:t})$ is $\mbox{NG}(m_t,C_t,a_t,b_t)$ where $m_t$, $C_t$, $a_t$, and $b_t$ are calculated through the following equations:
\begin{align}
f_t &= m_{t-1} &\qquad Q_t &= C_{t-1} + \lambda + 1 \label{eqn:obs.pred} \\
m_t &= (1 - C_t)f_t + C_ty_t &\qquad C_t &= 1 - \frac{1}{Q_t} \\
a_t &= a_{t-1} + \frac{1}{2} &\qquad b_t &= b_{t-1} + \frac{(y_t-f_t)^2}{2Q_t}
\end{align}
We can also calculate the marginal posterior distributions $p(x_t|y_{1:t})$ and $p(\theta|y_{1:t})$, given by
\begin{equation}
x_t|y_{1:t} \sim \mbox{T}(m_t,C_t \frac{b_t}{a_t},2a_t) \qquad \theta|y_{1:t} \sim \mbox{IG}(a_t, b_t), \label{eqn:margpost}
\end{equation}
and the one-step ahead predictive density $p(y_t|y_{1:t-1})$ using equation \eqref{eqn:obs.pred} since \[y_t|y_{1:t-1} \sim \mbox{T}(f_t,Q_t \frac{b_{t-1}}{a_{t-1}},2a_{t-1})\]
\noindent where $\mbox{T}(\mu,\sigma^2,d)$ represents the non-standard student-t distribution with location parameter $\mu$, scale parameter $\sigma^2$, and $d$ degrees of freedom.

To implement a particle learning algorithm to approximate $p(x_t,\theta|y_{1:t})$ for all $t$, we derive the following conditional distributions given the current state $x_t$ and fixed parameter $\theta$:
\begin{align*}
&y_{t+1}|x_t,\theta \sim \mbox{N}\left(x_t,\theta(1-\lambda)\right) \\
&x_{t+1}|y_{t+1},x_t,\theta \sim \mbox{N}(\mu_t,\tau^2)
\end{align*} 
where \[\mu_t = \frac{\lambda}{1+\lambda}(y_{t+1} + x_t / \lambda) \qquad \tau^2 = \theta\frac{\lambda}{1+\lambda}\]
\noindent We also note the conditional posterior for $\theta$:
\begin{equation}
\theta|y_{1:t+1},x_{0:t+1} \sim \mbox{IG}(a_{t+1},b_{t+1})
\end{equation}
\noindent where
\begin{align*}
a_t &= t + 1/2 + a_0, t \ge 1 \\
b_t &= \frac{1}{2}\left(\sum_{k=1}^t (y_k - x_k)^2 + \frac{1}{\lambda}\sum_{k=1}^t (x_k - x_{k-1})^2 + x_0^2\right) + b_0
\end{align*}
Thus, the sufficient statistics $a_t$ and $b_t$ are updated through the recursive map $S$ defined by
\begin{align*}
a_1 &= 3/2 + a_0 \qquad a_{t+1} = a_t + 1, t \ge 1 \\
b_1 &= \frac{1}{2}\left((y_1-x_1)^2 + \frac{1}{\lambda}(x_1-x_0)^2 + x_0^2\right) + b_0 \qquad b_{t+1} = \frac{1}{2}\left((y_{t+1}-x_{t+1})^2 + \frac{1}{\lambda}(x_{t+1}-x_t)^2\right) + b_t, t \ge 1
\end{align*}

To implement a Rao-Blackwellized version of the particle learning algorithm, we note the conditional sufficient statistics for $x_t|\theta$ given by $s_{x,t} = (m_t, C_t)$ where $m_0 = 0$, $C_0 = \theta$, and recursive updates are given by the Kalman filter equations:
\begin{align*}
m_{t+1} &= A_{t+1}y_{t+1} + (1-A_{t+1})m_t \\
C_{t+1} &= A_{t+1}\theta 
\end{align*}
\noindent where $A_{t+1} = \frac{C_t + \theta\lambda}{C_t + \theta(1+\lambda)}$. We then derive the following conditional distributions:
\begin{align*}
&y_{t+1}|s_{x,t},\theta \sim \mbox{N}\left(m_t, C_t + \theta(1-\lambda)\right) \\
&x_{t+1}|y_{t+1},s_{x,t},\theta \sim \mbox{N}(\tilde{\mu}_t,\tilde{\tau}^2)
\end{align*}
where \[\tilde{\mu}_t = \frac{\lambda}{1+\lambda}(y_{t+1} + m_t / \lambda) \qquad \tilde{\tau}^2 = \frac{\lambda}{1+\lambda}\left(\theta + \frac{C_t}{\lambda(1+\lambda)}\right)\]
\clearpage

\bibliographystyle{plainnat}
\bibliography{jarad}

\end{document} 