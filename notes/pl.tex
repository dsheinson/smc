\documentclass{article}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{graphicx}

\graphicspath{
{/Users/Danny/Documents/"UCSB - Research"/smc/graphs/dlmRW/},
{/Users/Danny/Documents/"UCSB - Research"/smc/graphs/}
}

\begin{document}

\section{Particle Learning}

We consider a particle filtering algorithm called particle learning \citep{Carv:Joha:Lope:Pols:part} that can be used for a particular class of state-space models which includes dynamic linear models (DLMs) \citep{petris2009dynamic}. These models are characterized by observation and state equations, specified by the distributions $p(y_t|x_t,\theta)$ and $p(x_t|x_{t-1},\theta)$, respectively, where $y_t$ represents observed data at time $t$, $x_t$ is the unobserved state, and $\theta$ represents any unknown fixed parameters. We are interested in approximating the \emph{filtered distribution} of the unknown states and fixed parameters at time $t$, i.e. $p(x_t,\theta|y_{1:t})$, through the discrete sample approximation
\begin{equation}
p(x_t,\theta|y_{1:t}) \approx \sum_{j=1}^J w_t^{(j)}\delta_{\left(x_t^{(j)},\theta_t^{(j)}\right)},
\end{equation}
where $\left(x_t^{(j)},\theta_t^{(j)}\right)$ represents sampled values corresponding to the $j^{\mbox{th}}$ particle, $w_t^{(j)}$ is the associated weight of the $j^{\mbox{th}}$ particle, and $\delta_x$ is a Dirac delta function that puts point mass at $x$. We require that $\sum_{j=1}^J w_t^{(j)} = 1$ for all $t$ and note that the subscript $t$ on $\theta_t^{(j)}$ does not imply that $\theta$ is dynamic, but rather that the sampled values for $\theta$ can change over time.

Like all other particle filters, particle learning prescribes a recursive formula for updating the discrete approximation to the filtered distribution over time. To avoid particle degeneracy in the fixed parameters, sampled values for $\theta$ are refreshed at each time point using conditional sufficient statistics. Let $s_t$ denote the sufficient statistics for $\theta$ conditional on the current state $x_t$. Then, we add the sampled values of the sufficient statistics, $s_t^{(j)}$, to the particles, i.e. particle $j$ and time $t$ is now represented by $\left(x_t^{(j)},s_t^{(j)},\theta_t^{(j)}\right)$. We move from an approximation to $p(x_t,\theta|y_{1:t})$ to that of $p(x_{t+1},\theta|y_{1:t+1})$ by the following procedure for each particle $j = 1,2,\ldots,J$:
\begin{enumerate}
\item Resample: sample an index $k \in \{1,\ldots,j,\ldots,J\}$ with associated probabilities $\{g_{t+1}^{(1)},\ldots,g_{t+1}^{(j)},\ldots,g_{t+1}^{(J)}\}$, where \[\tilde{g}_{t+1}^{(j)} = p\left(y_{t+1}|x_t^{(j)},\theta_t^{(j)}\right) \qquad g_{t+1}^{(j)} = \tilde{g}_{t+1}^{(j)} \left/ \sum_{l=1}^J \tilde{g}_{t+1}^{(l)}\right.,\]
\item Propagate: sample $x_{t+1}^{(j)} \sim p\left(x_{t+1}|y_{t+1},x_t^{(k)},\theta\right)$,
\item Update: calculate $s_{t+1}^{(j)} = S\left(y_{t+1},x_{t+1}^{(j)},s_t^{(k)}\right)$,
\item Regenerate: sample $\theta_{t+1}^{(j)} \sim p\left(\theta|s_{t+1}^{(j)}\right)$.
\end{enumerate}
The algorithm is initialized by specifying initial particles $\left(x_0^{(j)},s_0^{(j)},\theta_0^{(j)}\right)$ and weights $w_0^{(j)}$ for all $j$, usually done by sampling from the prior $p(x_0,\theta)$ with equal weights. Note that the algorithm requires the ability to evaluate the conditional predictive distribution $p(y_{t+1}|x_t,\theta)$ as well as the ability to sample from the conditional posterior distribution $p(x_{t+1}|y_{t+1},x_t,\theta)$. Thus, particle learning is only applicable to models for which the form of these distributions is analytically tractable. In addition, we must define the recursive map $S$ to update the sufficient statistics based on the new observation $y_{t+1}$ and the newly sampled state $x_{t+1}^{(j)}$.

Efficiency of the algorithm can be enhanced by marginalizing out the current state $x_t$ and tracking conditional state sufficient statistics. This process, known as Rao-Blackwellization, requires tractability of the distributions $p(y_{t+1}|s_{x,t},\theta)$, which is used in place of $p(y_{t+1}|x_t,\theta)$ in the ``Resample'' step, and $p(x_{t+1}|y_{t+1},s_{x,t},\theta)$, which is used in place of $p(x_{t+1}|y_{t+1},x_t,\theta)$ in the ``Propagate'' step, where $s_{x,t}$ is the conditional (on $\theta$) sufficient statistics for $x_t$. It is also necessary to define a recursive map $S_x$ for updating $s_{x,t}$ given $s_{x,t-1}$, $y_{t+1}$, and $\theta$.

Furthermore, the ``Resample'' step can be regarded as optional and only needed if particle weights are out of balance. For iterations of the algorithm for which we choose to forgo resampling, we 1) omit the ``Resample'' step, 2) replace all instances of the sampled index $k$ with the particle index $j$, and 3) add a final ``Calculate weights'' step where particle $j$ is assigned associated weight $w_{t+1}^{(j)}$, where \[\tilde{w}_{t+1}^{(j)} = w_t^{(j)}p\left(y_{t+1}|x_t^{(j)},\theta_t^{(j)}\right) \qquad w_{t+1}^{(j)} = \tilde{w}_{t+1}^{(j)} \left/ \sum_{l=1}^J \tilde{w}_{t+1}^{(l)}\right..\] If Rao-Blackwellization is performed, then $\tilde{w}_{t+1}^{(j)} = w_t^{(j)}p\left(y_{t+1}|s_{x,t}^{(j)},\theta_t^{(j)}\right)$ in the ``Calculate weights'' step.

\section{Example - local level DLM with common state and observation variance} \label{sec:ll}

For an illustration of particle learning, we consider the local level or random-walk DLM. In this example, an analytical form for $p(x_t,\theta|y_{1:t})$ exists, and so a particle filtering algorithm is not needed for this situation in practice. However, we offer this example so that we can evaluate the performance of particle learning through comparison with known distributions.

The local level model is specified by state and observation equations
\begin{align}
y_t &= x_t + v_t \label{eqn:llobs} \\
x_t &= x_{t-1} + w_t \label{eqn:llstate}
\end{align}
where $y_t$ and $x_t$ are univariate, $v_t \stackrel{\mbox{iid}}{\sim} \mbox{N}(0,\theta)$, $w_t \stackrel{\mbox{iid}}{\sim} \mbox{N}(0,\theta\lambda)$, and $v_t \perp w_s$ for all $s$ and $t$. We regard $\theta$ as an unknown parameter representing the common state and observation variance (up to a constant) and $\lambda$, which represents the signal to noise ratio, is regarded as known. We define the following prior distribution on the initial state $x_0$ and fixed parameter $\theta$:
\begin{equation}
x_0|\theta \sim \mbox{N}(m_0,\theta C_0) \qquad \theta \sim \mbox{IG}(a_0,b_0) \label{eqn:llprior}
\end{equation}
where $\mbox{IG}(a,b)$ represents the inverse-gamma distribution with shape parameter $a$ and rate parameter $b$. The hyperparameters $m_0$, $C_0$, $a_0$, and $b_0$ are regarded as known.

As mentioned, an explicit form for the posterior $p(x_t,\theta|y_{1:t})$ can be calculated and updated recursively using the well-known Kalman filter equations \cite[Chap. 2]{petris2009dynamic}. Denote the prior distribution $p(x_0, \theta)$ defined in equation \eqref{eqn:llprior} by $(x_0, \theta) \sim \mbox{NG}(m_0, C_0, a_0, b_0)$. Given $(x_{t-1},\theta)|y_{1:t-1} \sim \mbox{NG}(m_{t-1},C_{t-1}, a_{t-1}, b_{t-1})$ for $t \ge 1$ (with the convention $p(x_0,\theta|y_{1:0}) = p(x_0, \theta)$), the posterior distribution $p(x_t,\phi|y_{1:t})$ is $\mbox{NG}(m_t,C_t,a_t,b_t)$ where $m_t$, $C_t$, $a_t$, and $b_t$ are calculated through the following equations:
\begin{align}
f_t &= m_{t-1} &\qquad Q_t &= C_{t-1} + \lambda + 1 \label{eqn:obs.pred} \\
m_t &= (1 - C_t)f_t + C_ty_t &\qquad C_t &= 1 - \frac{1}{Q_t} \\
a_t &= a_{t-1} + \frac{1}{2} &\qquad b_t &= b_{t-1} + \frac{(y_t-f_t)^2}{2Q_t}
\end{align}
We can also calculate the marginal posterior distributions $p(x_t|y_{1:t})$ and $p(\theta|y_{1:t})$, given by
\begin{equation}
x_t|y_{1:t} \sim \mbox{T}(m_t,C_t \frac{b_t}{a_t},2a_t) \qquad \theta|y_{1:t} \sim \mbox{IG}(a_t, b_t), \label{eqn:margpost}
\end{equation}
and the one-step ahead predictive density $p(y_t|y_{1:t-1})$ using equation \eqref{eqn:obs.pred} since \[y_t|y_{1:t-1} \sim \mbox{T}(f_t,Q_t \frac{b_{t-1}}{a_{t-1}},2a_{t-1})\]
where $\mbox{T}(\mu,\sigma^2,d)$ represents the non-standard student-t distribution with location parameter $\mu$, scale parameter $\sigma^2$, and $d$ degrees of freedom.

To implement a particle learning algorithm to approximate $p(x_t,\theta|y_{1:t})$ for all $t$, we derive the following conditional distributions given the current state $x_t$ and fixed parameter $\theta$:
\begin{align*}
&y_{t+1}|x_t,\theta \sim \mbox{N}\left(x_t,\theta(1-\lambda)\right) \\
&x_{t+1}|y_{t+1},x_t,\theta \sim \mbox{N}(\mu_t,\tau^2)
\end{align*}
where \[\mu_t = \frac{\lambda}{1+\lambda}(y_{t+1} + x_t / \lambda) \qquad \tau^2 = \theta\frac{\lambda}{1+\lambda}\]
\noindent We also note the conditional posterior for $\theta$:
\begin{equation}
\theta|y_{1:t+1},x_{0:t+1} \sim \mbox{IG}(a_{t+1},b_{t+1})
\end{equation}
where
\begin{align*}
a_t &= t + 1/2 + a_0, t \ge 1 \\
b_t &= \frac{1}{2}\left(\sum_{k=1}^t (y_k - x_k)^2 + \frac{1}{\lambda}\sum_{k=1}^t (x_k - x_{k-1})^2 + x_0^2\right) + b_0
\end{align*}
Thus, the sufficient statistics $a_t$ and $b_t$ are updated through the recursive map $S$ defined by
\begin{align*}
a_1 &= 3/2 + a_0 \qquad a_{t+1} = a_t + 1, t \ge 1 \\
b_1 &= \frac{1}{2}\left((y_1-x_1)^2 + \frac{1}{\lambda}(x_1-x_0)^2 + x_0^2\right) + b_0 \qquad b_{t+1} = \frac{1}{2}\left((y_{t+1}-x_{t+1})^2 + \frac{1}{\lambda}(x_{t+1}-x_t)^2\right) + b_t, t \ge 1
\end{align*}

To implement a Rao-Blackwellized version of the particle learning algorithm, we note the conditional sufficient statistics for $x_t|\theta$ given by $s_{x,t} = (m_t, C_t)$, where $m_0 = 0$ and $C_0 = \theta$, and recursive updates given by the Kalman filter equations:
\begin{align*}
m_{t+1} &= A_{t+1}y_{t+1} + (1-A_{t+1})m_t \\
C_{t+1} &= A_{t+1}\theta
\end{align*}
where $A_{t+1} = \frac{C_t + \theta\lambda}{C_t + \theta(1+\lambda)}$. We then derive the following conditional distributions:
\begin{align*}
&y_{t+1}|s_{x,t},\theta \sim \mbox{N}\left(m_t, C_t + \theta(1-\lambda)\right) \\
&x_{t+1}|y_{t+1},s_{x,t},\theta \sim \mbox{N}(\tilde{\mu}_t,\tilde{\tau}^2)
\end{align*}
where \[\tilde{\mu}_t = \frac{\lambda}{1+\lambda}(y_{t+1} + m_t / \lambda) \qquad \tilde{\tau}^2 = \frac{\lambda}{1+\lambda}\left(\theta + \frac{C_t}{\lambda(1+\lambda)}\right)\]

\section{Example - DLM models with AR(1) error structure}

We now derive a particle learning algorithm for models for which $p(x_t,\theta|y_{1:t})$ is intractable. Consider the DLM given by
\begin{align}
y_t &= U_t\beta + F_tx_t + v_t \label{eqn:obs} \\
x_t &= \phi x_{t-1} + w_t \label{eqn:state}
\end{align}
where $U_t$ is a known $d$-length vector of covariates, $F_t$ is a known scalar, $\beta = (\beta_0,\beta_1,\ldots,\beta_{d-1})'$ is unknown, and $\phi$ is an unknown scalar. $U_t$ and $F_t$ are allowed to vary with time. With $y_t$, $x_t$, $v_t$, and $w_t$ defined the same way as in Section \ref{sec:ll}, the unknown fixed parameters are now defined by $\theta = (\beta',\phi,\sigma^2_s,\sigma^2_m)'$. The components of $\beta$ are defined on the whole real line while $\phi$ is restricted to $(-1,1)$ to ensure stationarity of the first-order autoregressive process for the state. The variances $\sigma^2_s$ and $\sigma^2_m$ are of course restricted to be non-negative. We define the prior on the initial state $x_0$ to come from the zero-mean stationary distribution of an AR(1) process given by $\mbox{N}(0,\frac{\sigma^2_s}{1-\phi^2})$.

To implement a particle learning algorithm with this model, we derive the conditional predictive and conditional posterior distributions
\begin{align*}
&y_{t+1}|x_t,\theta \sim \mbox{N}(U_{t+1}\beta + F_t\phi x_t, F_t^2\sigma^2_s + \sigma^2_m) \\
&x_{t+1}|y_{t+1},x_t,\theta \sim \mbox{N}(\mu_t,\tau^2)
\end{align*}
where \[\mu_t = \tau^2\left(\frac{(y_{t+1}-U_{t_1}\beta)F_{t+1}}{\sigma^2_m} + \frac{\phi x_t}{\sigma^2_s}\right) \qquad \tau^2 = \left(\frac{F_{t+1}^2}{\sigma^2_m} + \frac{1}{\sigma^2_s}\right)^{-1},\] and for a Rao-Blackwellized version, we use
\begin{align*}
&y_{t+1}|s_{x,t},\theta \sim \mbox{N}(U_{t+1}\beta,F_{t+1}\phi m_t, F_t^2(\phi^2 C_t + \sigma^2_s) + \sigma^2_m \\
&x_{t+1}|y_{t+1},s_{x,t},\theta \sim \mbox{N}(\tilde{\mu}_t,\tilde{\tau}^2)
\end{align*}
where \[\tilde{\mu}_t = \tau^2\left(\frac{(y_{t+1}-U_{t_1}\beta)F_{t+1}}{\sigma^2_m} + \frac{\phi m_t}{\sigma^2_s}\right) \qquad \tilde{\tau}^2 = \left(\frac{\sigma^2_m\phi}{F_{t+1}^2\sigma^2_s + \sigma^2_m}\right)^2C_t + \tau^2.\]
and $s_{x,t} = (m_t,C_t)$ (with $m_0 = 0$ and $C_0 = \frac{\sigma^2_s}{1-\phi^2}$) are the sufficient statistics for $x_t|\theta$ that can be updated by the recursive equations
\begin{align*}
&f_t = U_t\beta + F_t\phi m_{t-1} \qquad &Q_t = F_t^2(\phi^2C_{t-1} + \sigma^2_s) + \sigma^2_m \\
&m_t = A_t\frac{(y_t - U_t\beta)}{F_t} + (1 - A_t)\phi m_{t-1} \qquad &C_t = (\phi^2C_{t-1} + \sigma^2_s)(1 - A_t) \\
\end{align*}
where $A_t = \frac{F_t^2(\phi^2C_{t-1} + \sigma^2_s)}{F_t^2(\phi^2C_{t-1} + \sigma^2_s) + \sigma^2_m}$. Lastly, we derive the conditional distributions for $\theta$ using
\begin{align*}
p(\theta|y_{1:t},x_{0:t}) &= p(\beta,\phi,\sigma^2_s,\sigma^2_m|y_{1:t},x_{0:t}) \\
&\propto p(\beta,\phi,\sigma^2_s,\sigma^2_m,y_{1:t},x_{0:t}) \\
&= \left(\prod_{k=1}^t p(y_k|x_k,\beta,\sigma^2_m)p(x_k|x_{k-1},\phi,\sigma^2_s)\right)p(x_0|\phi,\sigma^2_s)p(\beta,\sigma^2_m)p(\phi,\sigma^2_s) \\
&= p(\beta,\sigma^2_m|y_{1:t},x_{0:t})p(\phi,\sigma^2_s|y_{1:t},x_{0:t})
\end{align*}
where the prior distributions on $\theta$ are given by
\begin{align*}
p(\beta,\phi,\sigma^2_s,\sigma^2_m) &= p(\beta,\sigma^2_m)p(\phi,\sigma^2_s) \\
p(\beta,\sigma^2_m) &= p(\beta|\sigma^2_m)p(\sigma^2_m) = \mbox{N}(\beta; b_0, \sigma^2_m B_0)\mbox{IG}(\sigma^2_m;a_{m_0},b_{m_0}) \\
p(\phi,\sigma^2_s) &= p(\phi|\sigma^2_s)p(\sigma^2_s) = \mbox{N}(\phi; \phi_0, \sigma^2_s \Phi_0)\mbox{IG}(\sigma^2_s;a_{s_0},b_{s_0})
\end{align*}
with the hyperparameters $b_0$, $B_0$, $\phi_0$, $\Phi_0$, $a_{m_0}$, $b_{m_0}$, $a_{s_0}$, and $b_{s_0}$ assumed known. The conditional posterior distributions for $\theta$ are then given by
\begin{align*}
p(\beta,\sigma^2_m|y_{1:t},x_{0:t}) &= \mbox{N}(\beta; b_t, \sigma^2_m B_t)\mbox{IG}(\sigma^2_m;a_{m_t},b_{m_t}) \\
p(\phi,\sigma^2_s|y_{1:t},x_{0:t}) &= \Psi(\phi,\sigma^2_s)\mbox{N}(\phi; \phi_t, \sigma^2_s \Phi_t)\mbox{IG}(\sigma^2_s;a_{s_t},b_{s_t}) \\
\end{align*}
where
\begin{align*}
b_t &= B_t\left(\sum_{k=1}^t U_k'(y_k - F_kx_k) + B_0^{-1}b_0\right) & B_t &= \left(\sum_{k=1}^t U_k'U_k + B_0^{-1}\right)^{-1} \\
a_{m_t} &= t/2 + a_{m_0} & b_{m_t} &= \frac{1}{2}\left(\sum_{k=1}^t (y_k - F_kx_k)^2 + b_0'B_0^{-1}b_0 + b_t'B_t^{-1}b_t\right) + b_{m_0} \\
\phi_t &= \Phi_t\left(\sum_{k=1}^t x_kx_{k-1} + \Phi_0^{-1}\phi_0\right) & \Phi_t &= \left(\sum_{k=1}^t x_{k-1}^2 + \Phi_0^{-1}\right)^{-1} \\
a_{s_t} &= (t+1)/2 + a_{s_0} & b_{s_t} &= \frac{1}{2}\left(\sum_{k=1}^t x_k^2 + \phi_0'\Phi_0^{-1}\phi_0 + \phi_t'\Phi_t^{-1}\phi_t\right) + b_{s_0} \\
\Psi(\phi,\sigma^2_s) &= \sqrt{1-\phi^2}\exp\left(-\frac{1-\phi^2}{2\sigma^2_s}x_0^2\right) & &
\end{align*}
While sampling from $p(\beta,\sigma^2_m|y_{1:t},x_{0:t})$ is straightforward, sampling from $p(\phi,\sigma^2_s|y_{1:t},x_{0:t})$ requires a Metropolis step where a joint sample $(\phi^*,{\sigma^2_s}^*)$ from $\mbox{N}(\phi; \phi_t, \sigma^2_s \Phi_t)\mbox{IG}(\sigma^2_s;a_{s_t},b_{s_t})$ is accepted with probability \[R = \mbox{min}\left[1,\frac{\Psi\left(\phi^*,{\sigma^2_s}^*\right)}{\Psi\left(\phi_{t-1}^{(j)},{\sigma^2_s}_{t-1}^{(j)}\right)}\right],\]
where $\left(\phi_{t-1}^{(j)},{\sigma^2_s}_{t-1}^{(j)}\right)$ are the values of $\phi$ and $\sigma^2_s$ for particle $j$ at time $t-1$. Sampling from these distributions requires tracking the sufficient statistics \[s_t = \left(\sum_{k=1}^t U_k'(y_k - F_kx_k),\sum_{k=1}^t U_k'U_k,\sum_{k=1}^t (y_k - F_kx_k)^2,\sum_{k=1}^t x_kx_{k-1},\sum_{k=1}^t x_{k-1}^2,\sum_{k=1}^t x_k^2,x_0\right)\] which are updated through the recursive map given by \[s_t = s_{t-1} + \left(U_t'(y_t - F_tx_t),U_t'U_t,(y_t - F_tx_t)^2,x_tx_{t-1},x_{t-1}^2,x_t^2,0\right)\]
Alternately, samples from $p(\theta|y_{1:t},x_{0:t})$ can be generated from the sample approximation to $p(\theta|y_{1:t-1},x_{0:t-1})$ using an MCMC scheme (see `fmri\_dlm.pdf' Section 2.2 steps 2-5 with $\tilde{V} = 1$, $q = 1$, $\tilde{X} = (x_0,\ldots,x_{t-1})'$, $\tilde{x} = (x_1,\ldots,x_t)'$, $m_0 = 0$, and $\tilde{C}_0 = (1-\phi^2)^{-1}$).

\clearpage

\bibliographystyle{plainnat}
\bibliography{jarad}

\end{document} 